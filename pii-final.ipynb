{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":66653,"databundleVersionId":7500999,"sourceType":"competition"},{"sourceId":7466758,"sourceType":"datasetVersion","datasetId":4332496},{"sourceId":7483989,"sourceType":"datasetVersion","datasetId":4356764},{"sourceId":7659420,"sourceType":"datasetVersion","datasetId":4459964},{"sourceId":163088908,"sourceType":"kernelVersion"},{"sourceId":171542624,"sourceType":"kernelVersion"}],"dockerImageVersionId":30636,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"class cfg:\n    TRAINING_MODEL_PATH = \"microsoft/deberta-v3-base\"\n    TRAINING_MAX_LENGTH = 1024\n    OUTPUT_DIR = \"output\"\n    seed = 42\n    use_fp16 = True\n    lr = 2e-5\n    epochs = 8\n    train_batch_size = 2\n    eval_batch_size = 2\n    accumulation_step = 2\n    weight_decay = 0.01 \n    scheduler = \"cosine\" \n    metric = \"fbeta\"\n    warmup_ratio = 0.1","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2025-10-25T06:03:38.603765Z","iopub.execute_input":"2025-10-25T06:03:38.604066Z","iopub.status.idle":"2025-10-25T06:03:38.614624Z","shell.execute_reply.started":"2025-10-25T06:03:38.604035Z","shell.execute_reply":"2025-10-25T06:03:38.613700Z"},"trusted":true},"outputs":[],"execution_count":1},{"cell_type":"code","source":"!pip install seqeval evaluate -q","metadata":{"execution":{"iopub.status.busy":"2025-10-25T06:03:38.616926Z","iopub.execute_input":"2025-10-25T06:03:38.617273Z","iopub.status.idle":"2025-10-25T06:03:51.877902Z","shell.execute_reply.started":"2025-10-25T06:03:38.617242Z","shell.execute_reply":"2025-10-25T06:03:51.876626Z"},"trusted":true},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import json\nimport argparse\nfrom itertools import chain\nfrom functools import partial\n\nimport os\nimport gc\nimport torch\nimport torch.nn as nn \nimport torch.nn.functional as F\nfrom sklearn.model_selection import train_test_split\nfrom transformers import AutoTokenizer, Trainer, TrainingArguments\nfrom transformers import AutoModelForTokenClassification, DataCollatorForTokenClassification\nimport evaluate\nfrom datasets import Dataset, features\nimport numpy as np\nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2025-10-25T06:03:51.879376Z","iopub.execute_input":"2025-10-25T06:03:51.879711Z","iopub.status.idle":"2025-10-25T06:04:09.902253Z","shell.execute_reply.started":"2025-10-25T06:03:51.879684Z","shell.execute_reply":"2025-10-25T06:04:09.901572Z"},"trusted":true},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"data = json.load(open(\"/kaggle/input/pii-detection-removal-from-educational-data/train.json\"))\n\nexternal = json.load(open(\"/kaggle/input/fix-punctuation-tokenization-external-dataset/pii_dataset_fixed.json\"))\nprint(\"external datapoints: \", len(external))\n\nmoredata = json.load(open(\"/kaggle/input/fix-punctuation-tokenization-external-dataset/moredata_dataset_fixed.json\"))\nprint(\"moredata datapoints: \", len(moredata))\n\nmore_more_data = json.load(open(\"/kaggle/input/pii-mixtral8x7b-generated-essays/mpware_mixtral8x7b_v1.1-no-i-username.json\"))\nprint(\"more_more_data datapoints: \", len(more_more_data))","metadata":{"execution":{"iopub.status.busy":"2025-10-25T06:04:09.903286Z","iopub.execute_input":"2025-10-25T06:04:09.903825Z","iopub.status.idle":"2025-10-25T06:04:14.375325Z","shell.execute_reply.started":"2025-10-25T06:04:09.903802Z","shell.execute_reply":"2025-10-25T06:04:14.374454Z"},"trusted":true},"outputs":[{"name":"stdout","text":"external datapoints:  4434\nmoredata datapoints:  2000\nmore_more_data datapoints:  2692\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# downsampling of negative examples\np=[] # positive samples (contain relevant labels)\nn=[] # negative samples (presumably contain entities that are possibly wrongly classified as entity)\nfor d in data:\n    if any(np.array(d[\"labels\"]) != \"O\"): p.append(d)\n    else: n.append(d)\nprint(\"original datapoints: \", len(data))","metadata":{"execution":{"iopub.status.busy":"2025-10-25T06:04:14.376483Z","iopub.execute_input":"2025-10-25T06:04:14.376778Z","iopub.status.idle":"2025-10-25T06:04:15.135396Z","shell.execute_reply.started":"2025-10-25T06:04:14.376753Z","shell.execute_reply":"2025-10-25T06:04:15.134425Z"},"trusted":true},"outputs":[{"name":"stdout","text":"original datapoints:  6807\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"data = moredata+external+ more_more_data +p+n[:len(n)//3]\nprint(\"combined: \", len(data))","metadata":{"execution":{"iopub.status.busy":"2025-10-25T06:04:15.136379Z","iopub.execute_input":"2025-10-25T06:04:15.136669Z","iopub.status.idle":"2025-10-25T06:04:15.143022Z","shell.execute_reply.started":"2025-10-25T06:04:15.136646Z","shell.execute_reply":"2025-10-25T06:04:15.142020Z"},"trusted":true},"outputs":[{"name":"stdout","text":"combined:  12025\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"P = 0.023797656310188375","metadata":{"execution":{"iopub.status.busy":"2025-10-25T06:04:15.146546Z","iopub.execute_input":"2025-10-25T06:04:15.147540Z","iopub.status.idle":"2025-10-25T06:04:15.155850Z","shell.execute_reply.started":"2025-10-25T06:04:15.147505Z","shell.execute_reply":"2025-10-25T06:04:15.155001Z"},"trusted":true},"outputs":[],"execution_count":7},{"cell_type":"code","source":"all_labels = sorted(list(set(chain(*[x[\"labels\"] for x in data]))))\nlabel2id = {l: i for i,l in enumerate(all_labels)}\nid2label = {v:k for k,v in label2id.items()}\n\ntarget = [\n    'B-EMAIL', 'B-ID_NUM', 'B-NAME_STUDENT', 'B-PHONE_NUM', \n    'B-STREET_ADDRESS', 'B-URL_PERSONAL', 'B-USERNAME', 'I-ID_NUM', \n    'I-NAME_STUDENT', 'I-PHONE_NUM', 'I-STREET_ADDRESS', 'I-URL_PERSONAL'\n]\n\nprint(id2label)","metadata":{"execution":{"iopub.status.busy":"2025-10-25T06:04:15.156878Z","iopub.execute_input":"2025-10-25T06:04:15.157141Z","iopub.status.idle":"2025-10-25T06:04:15.248889Z","shell.execute_reply.started":"2025-10-25T06:04:15.157119Z","shell.execute_reply":"2025-10-25T06:04:15.247933Z"},"trusted":true},"outputs":[{"name":"stdout","text":"{0: 'B-EMAIL', 1: 'B-ID_NUM', 2: 'B-NAME_STUDENT', 3: 'B-PHONE_NUM', 4: 'B-STREET_ADDRESS', 5: 'B-URL_PERSONAL', 6: 'B-USERNAME', 7: 'I-ID_NUM', 8: 'I-NAME_STUDENT', 9: 'I-PHONE_NUM', 10: 'I-STREET_ADDRESS', 11: 'I-URL_PERSONAL', 12: 'O'}\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"def tokenize(example, tokenizer, label2id, max_length):\n\n    # rebuild text from tokens\n    text = []\n    labels = []\n\n    for t, l, ws in zip(\n        example[\"tokens\"], example[\"provided_labels\"], example[\"trailing_whitespace\"]\n    ):\n        text.append(t)\n        labels.extend([l] * len(t))\n\n        if ws:\n            text.append(\" \")\n            labels.append(\"O\")\n\n    # actual tokenization\n    tokenized = tokenizer(\"\".join(text), return_offsets_mapping=True, max_length=max_length,truncation = True)\n\n    labels = np.array(labels)\n\n    text = \"\".join(text)\n    token_labels = []\n\n    for start_idx, end_idx in tokenized.offset_mapping:\n        # CLS token\n        if start_idx == 0 and end_idx == 0:\n            token_labels.append(label2id[\"O\"])\n            continue\n\n        # case when token starts with whitespace\n        if text[start_idx].isspace():\n            start_idx += 1\n\n        token_labels.append(label2id[labels[start_idx]])\n\n    length = len(tokenized.input_ids)\n\n    return {**tokenized, \"labels\": token_labels, \"length\": length}","metadata":{"execution":{"iopub.status.busy":"2025-10-25T06:04:15.250046Z","iopub.execute_input":"2025-10-25T06:04:15.250318Z","iopub.status.idle":"2025-10-25T06:04:15.263723Z","shell.execute_reply.started":"2025-10-25T06:04:15.250294Z","shell.execute_reply":"2025-10-25T06:04:15.262709Z"},"trusted":true},"outputs":[],"execution_count":9},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(cfg.TRAINING_MODEL_PATH)\n\nds = Dataset.from_dict({\n    \"full_text\": [x[\"full_text\"] for x in data],\n    \"document\": [str(x[\"document\"]) for x in data],\n    \"tokens\": [x[\"tokens\"] for x in data],\n    \"trailing_whitespace\": [x[\"trailing_whitespace\"] for x in data],\n    \"provided_labels\": [x[\"labels\"] for x in data],\n})\nds = ds.map(tokenize, fn_kwargs={\"tokenizer\": tokenizer, \"label2id\": label2id, \"max_length\": cfg.TRAINING_MAX_LENGTH}, num_proc=3)\n# ds = ds.class_encode_column(\"group\")","metadata":{"execution":{"iopub.status.busy":"2025-10-25T06:04:15.265006Z","iopub.execute_input":"2025-10-25T06:04:15.265656Z","iopub.status.idle":"2025-10-25T06:06:08.205367Z","shell.execute_reply.started":"2025-10-25T06:04:15.265621Z","shell.execute_reply":"2025-10-25T06:06:08.204395Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f552f91d9a94a16980ad8d11c38e32b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/579 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2cf0eee7023e417898033b69cad40343"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8309bcec2c6547eb8fd1422f66cfb9e9"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:473: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"    ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#0:   0%|          | 0/4009 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e5bd0a8aa4d480bbec2ca18984a5976"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#1:   0%|          | 0/4008 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"26c57696ba6342359eeceb661bb7ec5a"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#2:   0%|          | 0/4008 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f625a30dd9494751a84c9990b3662e96"}},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"x = ds[0]\n\nfor t,l in zip(x[\"tokens\"], x[\"provided_labels\"]):\n    if l != \"O\":\n        print((t,l))\n\nprint(\"*\"*100)\n\nfor t, l in zip(tokenizer.convert_ids_to_tokens(x[\"input_ids\"]), x[\"labels\"]):\n    if id2label[l] != \"O\":\n        print((t,id2label[l]))","metadata":{"execution":{"iopub.status.busy":"2025-10-25T06:06:08.206885Z","iopub.execute_input":"2025-10-25T06:06:08.207244Z","iopub.status.idle":"2025-10-25T06:06:08.218805Z","shell.execute_reply.started":"2025-10-25T06:06:08.207209Z","shell.execute_reply":"2025-10-25T06:06:08.217811Z"},"trusted":true},"outputs":[{"name":"stdout","text":"('Richard', 'B-NAME_STUDENT')\n('Chang', 'I-NAME_STUDENT')\n('Richard', 'B-NAME_STUDENT')\n('gwilliams@yahoo.com', 'B-EMAIL')\n('brandy38', 'B-USERNAME')\n('Richard', 'B-NAME_STUDENT')\n('GB41EJEY19489241157815', 'B-ID_NUM')\n('Richard', 'B-NAME_STUDENT')\n('Richard', 'B-NAME_STUDENT')\n('(', 'B-PHONE_NUM')\n('259)938', 'I-PHONE_NUM')\n('-', 'I-PHONE_NUM')\n('7784x08016', 'I-PHONE_NUM')\n('Richard', 'B-NAME_STUDENT')\n('Richard', 'B-NAME_STUDENT')\n('https://twitter.com/john51', 'B-URL_PERSONAL')\n('Richard', 'B-NAME_STUDENT')\n('Richard', 'B-NAME_STUDENT')\n('Richard', 'B-NAME_STUDENT')\n('https://youtube.com/c/sallywalker', 'B-URL_PERSONAL')\n('Richard', 'B-NAME_STUDENT')\n('Richard', 'B-NAME_STUDENT')\n('711', 'B-STREET_ADDRESS')\n('Golden', 'I-STREET_ADDRESS')\n('Overpass', 'I-STREET_ADDRESS')\n(',', 'I-STREET_ADDRESS')\n('West', 'I-STREET_ADDRESS')\n('Andreaville', 'I-STREET_ADDRESS')\n(',', 'I-STREET_ADDRESS')\n('OH', 'I-STREET_ADDRESS')\n('44115', 'I-STREET_ADDRESS')\n('Richard', 'B-NAME_STUDENT')\n('Richard', 'B-NAME_STUDENT')\n('Chang', 'I-NAME_STUDENT')\n('Richard', 'B-NAME_STUDENT')\n('Richard', 'B-NAME_STUDENT')\n****************************************************************************************************\n('▁Richard', 'B-NAME_STUDENT')\n('▁Chang', 'I-NAME_STUDENT')\n('▁Richard', 'B-NAME_STUDENT')\n('▁g', 'B-EMAIL')\n('william', 'B-EMAIL')\n('s', 'B-EMAIL')\n('@', 'B-EMAIL')\n('yahoo', 'B-EMAIL')\n('.', 'B-EMAIL')\n('com', 'B-EMAIL')\n('▁brandy', 'B-USERNAME')\n('38', 'B-USERNAME')\n('▁Richard', 'B-NAME_STUDENT')\n('▁GB', 'B-ID_NUM')\n('41', 'B-ID_NUM')\n('EJ', 'B-ID_NUM')\n('EY', 'B-ID_NUM')\n('1948', 'B-ID_NUM')\n('924', 'B-ID_NUM')\n('11', 'B-ID_NUM')\n('578', 'B-ID_NUM')\n('15', 'B-ID_NUM')\n('▁Richard', 'B-NAME_STUDENT')\n('▁Richard', 'B-NAME_STUDENT')\n('▁(', 'B-PHONE_NUM')\n('259', 'I-PHONE_NUM')\n(')', 'I-PHONE_NUM')\n('938', 'I-PHONE_NUM')\n('-', 'I-PHONE_NUM')\n('778', 'I-PHONE_NUM')\n('4', 'I-PHONE_NUM')\n('x', 'I-PHONE_NUM')\n('080', 'I-PHONE_NUM')\n('16', 'I-PHONE_NUM')\n('▁Richard', 'B-NAME_STUDENT')\n('▁Richard', 'B-NAME_STUDENT')\n('▁https', 'B-URL_PERSONAL')\n(':', 'B-URL_PERSONAL')\n('/', 'B-URL_PERSONAL')\n('/', 'B-URL_PERSONAL')\n('twitter', 'B-URL_PERSONAL')\n('.', 'B-URL_PERSONAL')\n('com', 'B-URL_PERSONAL')\n('/', 'B-URL_PERSONAL')\n('john', 'B-URL_PERSONAL')\n('51', 'B-URL_PERSONAL')\n('▁Richard', 'B-NAME_STUDENT')\n('▁Richard', 'B-NAME_STUDENT')\n('▁Richard', 'B-NAME_STUDENT')\n('▁https', 'B-URL_PERSONAL')\n(':', 'B-URL_PERSONAL')\n('/', 'B-URL_PERSONAL')\n('/', 'B-URL_PERSONAL')\n('youtube', 'B-URL_PERSONAL')\n('.', 'B-URL_PERSONAL')\n('com', 'B-URL_PERSONAL')\n('/', 'B-URL_PERSONAL')\n('c', 'B-URL_PERSONAL')\n('/', 'B-URL_PERSONAL')\n('s', 'B-URL_PERSONAL')\n('ally', 'B-URL_PERSONAL')\n('walker', 'B-URL_PERSONAL')\n('▁Richard', 'B-NAME_STUDENT')\n('▁Richard', 'B-NAME_STUDENT')\n('▁711', 'B-STREET_ADDRESS')\n('▁Golden', 'I-STREET_ADDRESS')\n('▁Over', 'I-STREET_ADDRESS')\n('pass', 'I-STREET_ADDRESS')\n(',', 'I-STREET_ADDRESS')\n('▁West', 'I-STREET_ADDRESS')\n('▁Andrea', 'I-STREET_ADDRESS')\n('ville', 'I-STREET_ADDRESS')\n(',', 'I-STREET_ADDRESS')\n('▁OH', 'I-STREET_ADDRESS')\n('▁44', 'I-STREET_ADDRESS')\n('115', 'I-STREET_ADDRESS')\n('▁Richard', 'B-NAME_STUDENT')\n('▁Richard', 'B-NAME_STUDENT')\n('▁Chang', 'I-NAME_STUDENT')\n('▁Richard', 'B-NAME_STUDENT')\n('▁Richard', 'B-NAME_STUDENT')\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"from seqeval.metrics import recall_score, precision_score\nfrom seqeval.metrics import classification_report\nfrom seqeval.metrics import f1_score\n\ndef compute_metrics(p, all_labels):\n    predictions, labels = p\n    predictions = np.argmax(predictions, axis=2)\n\n    # Remove ignored index (special tokens)\n    true_predictions = [\n        [all_labels[p] for (p, l) in zip(prediction, label) if l != -100]\n        for prediction, label in zip(predictions, labels)\n    ]\n    true_labels = [\n        [all_labels[l] for (p, l) in zip(prediction, label) if l != -100]\n        for prediction, label in zip(predictions, labels)\n    ]\n    \n    recall = recall_score(true_labels, true_predictions)\n    precision = precision_score(true_labels, true_predictions)\n    fbeta_score = (1 + 5*5) * recall * precision / (5*5*precision + recall)\n    \n    results = {\n        'recall': recall,\n        'precision': precision,\n        'fbeta': fbeta_score\n    }\n    return results","metadata":{"execution":{"iopub.status.busy":"2025-10-25T06:06:08.220132Z","iopub.execute_input":"2025-10-25T06:06:08.220690Z","iopub.status.idle":"2025-10-25T06:06:08.240971Z","shell.execute_reply.started":"2025-10-25T06:06:08.220658Z","shell.execute_reply":"2025-10-25T06:06:08.240072Z"},"trusted":true},"outputs":[],"execution_count":12},{"cell_type":"code","source":"model = AutoModelForTokenClassification.from_pretrained(\n    cfg.TRAINING_MODEL_PATH,\n    num_labels=len(all_labels),\n    id2label=id2label,\n    label2id=label2id,\n    ignore_mismatched_sizes=True\n)\ncollator = DataCollatorForTokenClassification(tokenizer, pad_to_multiple_of=16)","metadata":{"execution":{"iopub.status.busy":"2025-10-25T06:06:08.242194Z","iopub.execute_input":"2025-10-25T06:06:08.242567Z","iopub.status.idle":"2025-10-25T06:06:10.591526Z","shell.execute_reply.started":"2025-10-25T06:06:08.242541Z","shell.execute_reply":"2025-10-25T06:06:10.590596Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/371M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"54d5bd7499aa435f9c910a05a6582c91"}},"metadata":{}},{"name":"stderr","text":"Some weights of DebertaV2ForTokenClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# I actually chose to not use any validation set. This is only for the model I use for submission.\nargs = TrainingArguments(\n    logging_dir = './logs',\n    output_dir=cfg.OUTPUT_DIR, \n    fp16=cfg.use_fp16,\n    learning_rate=cfg.lr,\n    num_train_epochs=cfg.epochs,\n    per_device_train_batch_size=cfg.train_batch_size,\n    gradient_accumulation_steps=cfg.accumulation_step,\n    report_to=\"none\",\n    evaluation_strategy=\"no\",\n    do_eval=False,\n    save_total_limit=1,\n    logging_steps=500,\n    lr_scheduler_type=cfg.scheduler,\n    metric_for_best_model=cfg.metric,\n    greater_is_better=True,\n    warmup_ratio=cfg.warmup_ratio,\n    weight_decay=cfg.weight_decay,\n)\n","metadata":{"execution":{"iopub.status.busy":"2025-10-25T06:06:10.593182Z","iopub.execute_input":"2025-10-25T06:06:10.593561Z","iopub.status.idle":"2025-10-25T06:06:10.628159Z","shell.execute_reply.started":"2025-10-25T06:06:10.593527Z","shell.execute_reply":"2025-10-25T06:06:10.627405Z"},"trusted":true},"outputs":[],"execution_count":14},{"cell_type":"code","source":"class MyCustomTrainer(Trainer):\n    def compute_loss(self, model, inputs, return_outputs=False):\n        labels = inputs.get(\"labels\")\n        outputs = model(**inputs)\n        logits = outputs.get(\"logits\")\n        \n        pred = F.softmax(logits, dim=-1)\n        b_term_tensor = torch.zeros_like(pred)\n        b_term = (5**2)*(P/(1-P))\n        b_term_tensor[:, :, 12] = b_term       \n\n        loss = F.nll_loss((pred + b_term_tensor).log().transpose(1, 2), labels)\n        \n        return (loss, outputs) if return_outputs else loss","metadata":{"execution":{"iopub.status.busy":"2025-10-25T06:06:10.629229Z","iopub.execute_input":"2025-10-25T06:06:10.629527Z","iopub.status.idle":"2025-10-25T06:06:10.635477Z","shell.execute_reply.started":"2025-10-25T06:06:10.629503Z","shell.execute_reply":"2025-10-25T06:06:10.634458Z"},"trusted":true},"outputs":[],"execution_count":15},{"cell_type":"code","source":"trainer = MyCustomTrainer(\n    model=model, \n    args=args, \n    train_dataset=ds,\n    data_collator=collator, \n    tokenizer=tokenizer,\n    compute_metrics=partial(compute_metrics, all_labels=all_labels),\n)\ntrainer.train()\ntrainer.save_model(f\"deberta3base_1024\")\ntokenizer.save_pretrained(f\"deberta3base_1024\")\ndel trainer\ndel model\ngc.collect()\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2025-10-25T06:06:10.636511Z","iopub.execute_input":"2025-10-25T06:06:10.636783Z","execution_failed":"2025-10-25T08:28:28.413Z"},"trusted":true},"outputs":[{"name":"stderr","text":"You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='3462' max='24048' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 3462/24048 38:33 < 3:49:26, 1.50 it/s, Epoch 1.15/8]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>-0.111100</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>-0.439000</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>-0.444500</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>-0.445700</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>-0.447500</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>-0.447000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}}],"execution_count":null}]}